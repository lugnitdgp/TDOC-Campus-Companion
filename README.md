# ğŸ“ Campus Companion

**AI-Powered Campus Information Assistant for NIT Durgapur**

---

## ğŸ› ï¸ Tech Stack

| Component | Technology |
|-----------|-----------|
| **Backend API** | FastAPI + Uvicorn |
| **Database** | SQLite3 |
| **Vector Storage** | ChromaDB (internally using SQLite3) |
| **Embeddings** | Sentence Transformers â†’ 384-dim vectors |
| **Frontend** | Streamlit |
| **PDF Loading** | PyPDF Loader |
| **Classification** | Keyword â†’ Logistic Regression (ML) â†’ LLM |
| **LLM** | Open Source Model from HuggingFace: Mistral-7B-Instruct |

---

## ğŸ“Š System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     CAMPUS COMPANION SYSTEM                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  USER QUERY â†’ FastAPI Backend â†’ 3-Level Classification           â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  INTENT CLASSIFIER (core/classifier.py)                    â”‚  â”‚
â”‚  â”‚                                                            â”‚  â”‚
â”‚  â”‚  Level 1: Keyword Matching (âš¡ 0.001s) - 70% queries        â”‚  â”‚
â”‚  â”‚  Level 2: ML Classifier (âš¡âš¡ 0.01s) - 25% queries           â”‚  â”‚
â”‚  â”‚  Level 3: LLM (Mistral-7B) (âš¡âš¡âš¡ 1-2s) - 5% queries         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                         â”‚                                        â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚         â–¼               â–¼               â–¼                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚  â”‚ DATABASE   â”‚  â”‚ RAG SYSTEM â”‚  â”‚ AI FALLBACKâ”‚                  â”‚
â”‚  â”‚            â”‚  â”‚            â”‚  â”‚            â”‚                  â”‚ 
â”‚  â”‚ â€¢ Canteen  â”‚  â”‚ â€¢ ChromaDB â”‚  â”‚ Mistral-7B â”‚                  â”‚
â”‚  â”‚ â€¢ Faculty  â”‚  â”‚ â€¢ 384-dim  â”‚  â”‚ Generates  â”‚                  â”‚
â”‚  â”‚ â€¢ Rooms    â”‚  â”‚   Vectors  â”‚  â”‚ Responses  â”‚                  â”‚
â”‚  â”‚ â€¢ Wardens  â”‚  â”‚ â€¢ Cosine   â”‚  â”‚            â”‚                  â”‚
â”‚  â”‚ (SQLite)   â”‚  â”‚   Search   â”‚  â”‚            â”‚                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚        â”‚               â”‚               â”‚                         â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â”‚                        â–¼                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  AI RESPONSE FORMATTER (core/response.py)                  â”‚  â”‚
â”‚  â”‚  Raw Data â†’ Natural Language (Mistral-7B, Temp: 0.5)       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                       â–¼                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  JSON RESPONSE                                             â”‚  â”‚
â”‚  â”‚  {"answer": "...", "intent": "...", "confidence": 0.85}    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Project Structure

```
CAMPUS_COMPANION/
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ main.py                    # FastAPI app initialization
â”‚   â””â”€â”€ routers/
â”‚       â””â”€â”€ chat.py                # â­ Main chat endpoint (600+ lines)
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ classifier.py              # â­ 3-level intent classification (800+ lines)
â”‚   â”œâ”€â”€ rag.py                     # â­ RAG system with ChromaDB (190+ lines)
â”‚   â”œâ”€â”€ response.py                # ğŸ¤– AI response formatter
â”‚   â”œâ”€â”€ fallback_message.py        # ğŸ›¡ï¸ AI fallback handler
â”‚   â””â”€â”€ embeddings.py              # Document chunking & embeddings
â”œâ”€â”€ db/
â”‚   â”œâ”€â”€ models.py                  # â­ Database schema (10 tables)
â”‚   â””â”€â”€ session.py                 # DB connection
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ ingest_pdfs.py             # PDF â†’ ChromaDB pipeline
â”‚   â”œâ”€â”€ pdf_processor.py           # Text extraction (PyPDF2 + Tesseract)
â”‚   â””â”€â”€ chunking.py                # Text chunking logic
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ pdfs/                      # Source PDF documents
â”‚   â””â”€â”€ rag_docs/                  # ChromaDB storage
â”œâ”€â”€ frontend.py                    # Streamlit chat UI
â”œâ”€â”€ app.py                         # Database initializer
â”œâ”€â”€ testdb.py                      # Sample data loader
â”œâ”€â”€ requirements.txt               # Python dependencies
â”œâ”€â”€ .env                           # Environment variables
â””â”€â”€ campus_companion.db            # SQLite database
```

---

## ğŸš€ Quick Start Guide

### ï¿½ï¿½ Prerequisites

Verify the following are installed:

```bash
python3 --version    
pip --version
git --version
```

### ğŸ”§ Installation

**1. Clone and Navigate**
```bash
git clone <your-repo-url>
cd CAMPUS_COMPANION
```

**2. Create Virtual Environment**
```bash
# Create virtual environment
python3 -m venv .venv

# Activate (Linux/Mac)
source .venv/bin/activate

# Activate (Windows)
.venv\Scripts\activate
```

**3. Install Dependencies**
```bash
pip install -r requirements.txt
```

**4. Set Up HuggingFace Token**
1. Visit: https://huggingface.co/settings/tokens
2. Create token (Read access)
3. Copy token
4. Create `.env` file:
```bash
echo "HUGGINGFACEHUB_API_TOKEN=hf_paste_your_token_here" > .env
```

**5. Initialize Database**
```bash
python3 app.py
python3 testdb.py
```

**6. Set Up PDF Documents**
```bash
mkdir -p data/pdfs
# Add your PDF documents to data/pdfs/
# Then run:
python3 scripts/ingest_pdfs.py
```

**7. Start Backend**
```bash
uvicorn api.main:app --reload
```

**8. Test API** (in new terminal)
```bash
curl -X POST http://localhost:8000/api/chat \
  -H "Content-Type: application/json" \
  -d '{"text":"hello"}'
```

**9. Start Frontend** (in another terminal with `.venv` activated)
```bash
streamlit run frontend.py
```

---

## ğŸ“š Implementation Guide

### ğŸ“… DAY 1: Database Setup & AI Fallback

**ğŸ¯ Learning Objectives:**
- Understand the 3-level intent classification system
- Learn database structure and queries
- Implement AI fallback for graceful error handling

#### ğŸ” The Problem
How does the system know what type of question was asked?

**Solution:** Progressive complexity with fallback

#### ğŸ† Three-Level Classification System

##### **Level 1: Keyword Matching** âš¡ (Fast - 0.001s)
- **Handles:** 70% of queries
- **Method:** Simple word detection
- **Function:** `classify_keyword()` in `classifier.py`

**Examples:**
- âœ… "Roy canteen phone" â†’ Keywords found â†’ `db_contact`
- âœ… "Where is AB-301?" â†’ Keywords found â†’ `db_location`
- âŒ "I need to contact the mess" â†’ No exact keywords

##### **Level 2: Machine Learning** âš¡âš¡ (Medium - 0.01s)
- **Handles:** 25% of queries
- **Method:** TF-IDF + Logistic Regression
- **Training:** Pre-trained on 200+ example queries
- **Function:** `ml_classify()` in `classifier.py`

**How it works:**
- Converts text to numerical features (word importance)
- Trained model predicts intent
- Example: "mess contact" â†’ ML recognizes as contact query

**When it works:**
- âœ… Variations of known patterns
- âœ… Synonyms and paraphrases

**When it fails:**
- âŒ Completely novel phrasing
- âŒ Ambiguous questions

##### **Level 3: LLM Classification** âš¡âš¡âš¡ (Slow ~ 1-2s) [HW]

**Hints:**
- Sends query to Mistral-7B with instructions
- "Classify this as: contact/location/rag/small_talk/fallback"
- Returns intent with reasoning

**Example:**
- "Can you help me reach the person in charge of food services?" â†’ LLM understands context â†’ `db_contact`

#### ğŸ—„ï¸ Database Structure

**How to create the DB:**
1. Create table models in `models.py`
2. Use `session.py` to connect
3. Populate db by forming `testdb.py`

**What's in the Database?**
- 8-10 tables in SQLite: Faculty, Canteen, Warden, Room, Building, etc.
- Fixed schema (columns known in advance)
- Fast exact matches

**Key Functions:**
- `try_get_contact(text, session)` - Search people/places
- `try_get_location(text, session)` - Search rooms/buildings
- `extract_entity_names()` - Parse query for names

#### ğŸ›¡ï¸ AI Fallback System

**Concept:** Graceful handling of out-of-scope queries

**When Fallback Triggers:**
- Intent classified as "ai_fallback"
- Database search returns nothing
- RAG search finds no relevant documents
- Confidence too low (< 0.3)

**Response Generation:**
- Send query + system prompt to Mistral-7B
- Temperature: 0.7 (more creative for deflection)
- AI generates polite refusal + redirection + organized response

**Key Function:** `fallback_ai_response(query)` in `fallback_message.py`

#### ğŸ§ª Hands-on Exercise

Edit `testdb.py` and add/populate data of your choice

**Functions Involved:**
- `session.add()` - Add to database
- `session.commit()` - Save changes
- `try_get_contact()` - Search function

---

### ğŸ“… DAY 2: RAG (Retrieval Augmented Generation)

**ğŸ¯ Learning Objectives:**
- Understand RAG (Retrieval Augmented Generation) concept
- Learn PDF processing pipeline (extraction â†’ chunking â†’ embedding)
- Understand semantic search and cosine similarity

#### ğŸ¤” The Problem

**Student asks:** "How to calculate CGPA?"

**Why Database Won't Work:**
- âŒ CGPA calculation is a multi-step explanation (not a single data point)
- âŒ Rules are in PDF documents (Academic Handbook, 50+ pages)
- âŒ Manual data entry = tedious + error-prone
- âŒ Rules change â†’ Need to update database every time

**Why not raw AI?**
- âŒ LLMs hallucinate
- âŒ No existing knowledge of the campus rules
- âŒ CGPA varies from campus to campus

#### ğŸ”„ RAG Pipeline

**Document Processing:**
```
PDFs â†’ Extract Text â†’ Split into Chunks â†’ Convert to Vectors â†’ Store in Database
```

**Query Processing:**
```
User Question â†’ Convert to Vector â†’ Find Similar Vectors â†’ Get Text Chunks
Question + Context Chunks â†’ LLM â†’ Natural Answer
```

#### ğŸ“„ PDF Processing Pipeline

##### **1. PDF Text Extraction**

**Process:**
1. Open PDF file
2. Iterate through each page
3. Extract text layer (embedded text data)
4. Concatenate all pages

**Key Function:** `extract_text_pypdf2()` in `pdf_processor.py`

##### **2. Text Cleaning**

**Removes Noise:**
- Page numbers
- URLs
- Headers/footers
- Extra whitespaces

**Key Function:** `clean_text()` in `pdf_processor.py`

##### **3. Quality Check**

Check the length of answer and whether it is in readable format

**Key Function:** `validate_extracted_text()` in `pdf_processor.py`

#### âœ‚ï¸ Text Chunking

**Why Chunking?**
- Embedding models have token limits for each query
- Semantic search less accurate with more tokens
- Higher API cost with larger inputs

**Solution:** Split into smaller, semantically meaningful pieces

**Chunking Parameters:**
- `chunk_size`
- `chunk_overlap`
- `min_chunk_size`

**Key Function:** `chunk_text()` in `chunking.py`

#### ğŸ”¢ Embeddings

**Model Used:** `all-MiniLM-L6-v2` (Sentence Transformers)

**Concept:** Convert text into numbers that capture meaning

**Example:**
```
Text: "How to calculate CGPA?"
Embedding: [0.234, -0.112, 0.567, ..., 0.891]  (384 numbers)

"CGPA calculation" â†’ [0.12, 0.45, -0.23, ...]
"Grade point average" â†’ [0.15, 0.43, -0.20, ...]  (CLOSE! âœ…)
"Pizza recipe" â†’ [0.87, -0.32, 0.61, ...]  (FAR! âŒ)
```

**Key Functions:**
- `get_embeddings()` in `embeddings.py`
- `generate_embeddings()` in `embeddings.py`

#### ğŸ—ƒï¸ Vector Database - ChromaDB

Stores all the embeddings for semantic search

#### ğŸ§ª Hands-on Exercise

```bash
# 1. Add PDF to data folder
cp ~/hostel_rules.pdf data/pdfs/

# 2. Run ingestion
python3 scripts/ingest_pdfs.py

# 3. Check ChromaDB
python3 -c "from core.rag import collection; print(f'{collection.count()} documents')"

# 4. Test query
curl -X POST http://localhost:8000/api/chat \
  -d '{"text":"What are hostel visiting hours?"}'
```

---

### ğŸ“… DAY 3: Intent Classifier

**ğŸ¯ Learning Objectives:**
- Master the unified classification system
- Understand the priority-based keyword matching
- Learn ML-based intent prediction
- Explore result aggregation strategies

#### ğŸ¤” The Problem

When a user asks "Roy canteen phone", how does the system know they want contact information and not location or rules?

**Solution:** Intent Classification - categorizing user queries into predefined intents

#### ğŸ¯ Intent Types in Campus Companion

| Intent | Description |
|--------|-------------|
| `db_contact` | Contact information (phone, email) |
| `db_location` | Location queries (rooms, buildings) |
| `rag` | Document-based questions (CGPA rules, policies) |
| `ai_fallback` | General questions / greetings |
| `small_talk` | [HW] Conversational queries |

#### ğŸ”„ Three-Level Classification Pipeline

```
Keyword Matching (Fast) â†’ Machine Learning (Accurate) â†’ LLM (Slow but most Accurate) [HW]
```

#### ğŸ”‘ Keyword Classification

**Function:** `classify_keywords(text: str) -> IntentResult`

**Purpose:** Fast rule-based classification using keyword matching

**Priority Order (Matters!):**
1. âœ… Check for RAG keywords â†’ "CGPA", "rules", "policy"
2. âœ… Check for contact keywords â†’ "phone", "email", "canteen"
3. âœ… Check for location keywords â†’ "where", "room", "building"
4. âœ… Default â†’ `ai_fallback`

**Why this order?**
- RAG first because academic queries are most specific
- Contact/Location second because they have clear entities
- Fallback last as catch-all

#### ğŸ¤– Machine Learning Classifier

**Key Class:** `MLClassifier`

**Purpose:** Learn patterns from training examples using Machine Learning

**Components:**
1. **TF-IDF Vectorizer** - Converts text to numerical features
2. **Logistic Regression** - Predicts intent based on learned patterns

#### ğŸ¼ The Orchestrator

**Function:** `UnifiedClassifier.classify()`

**Purpose:** Combine all three classifiers and make final decision

**Classification Pipeline:**
```
Step 1: Run keyword classifier (always)
  â†“
Step 2: Run ML classifier (if trained)
  â†“
Step 3: Run LLM classifier (if requested AND confidence < 0.7)
  â†“
Step 4: Aggregate results by taking MAX confidence per intent
  â†“
Step 5: Detect multi-intent queries
  â†“
Step 6: Determine if AI fallback needed
  â†“
Return ClassificationResult
```

#### ğŸ“Š Result Aggregation Strategy

**Why MAX (not AVG)?**

- If one classifier is very confident, it likely found a strong signal
- Average would dilute strong predictions
- **Example:** Keyword (0.90) + ML (0.60) â†’ MAX = 0.90 (better than AVG = 0.75)

**[HW]** Multi-intent Discussion

---

### ğŸ“… DAY 4: Response Generation + Frontend

**ğŸ¯ Learning Objectives:**
- Understand how raw data is converted to natural language responses
- Learn the role of AI in response formatting
- Understand the frontend-backend connection

#### ğŸ¤” The Problem

**Database returns raw data for "Roy canteen phone":**

```
Raw Output:
name: Roy Canteen
phone: +91-8012345678
email: roy@campus.edu
location: Ground Floor
```

- **User Experience:** âŒ Boring, mechanical, not conversational
- **What Users Expect:** âœ… Natural, helpful, human-like response

#### ğŸ’¡ The Solution: AI Response Formatter

**Output:**
```
ğŸ½ï¸ Roy Canteen

You can reach Roy Canteen at +91-8012345678 or email them at 
roy@campus.edu. They're located on the Ground Floor!
```

#### ğŸ”„ Response Flow

```
RAW DATA (from DB/RAG)
    â†“
AI FORMATTER (response.py)
    â†“
NATURAL LANGUAGE RESPONSE
    â†“
FRONTEND (frontend.py)
    â†“
USER SEES POLISHED ANSWER
```

#### ğŸ¤– AI Response Formatter Architecture

**Key Class:** `ResponseGenerator` in `response.py`

##### **Main Methods:**

**1. `__init__()` - Initialization**
- Purpose: Set up LLM (Mistral-7B) and RAG system

**2. `refine_query(query: str) -> str`**
- Purpose: Improve search queries before RAG lookup

**3. `format_response(query: str, data: str) -> str`**
- Purpose: Convert raw data to natural language

**4. `generate_rag_response(query: str) -> Dict`**
- Purpose: Complete RAG pipeline - search docs + generate answer

##### **Helper Functions:**

**`_build_context(documents, max_length)`**
- Combines document chunks into one string
- Stops at 2000 chars (LLM context limit)
- Labels each source: [Source 1], [Source 2], etc.

**`_generate_llm_answer(query, context)`**
- Sends context + query to Mistral-7B
- Prompt engineering: "Answer using ONLY context"
- Prevents hallucination (AI making up facts)

**`_calculate_confidence(documents)`**
- Average relevance score of top 3 chunks
- Example: (0.92 + 0.87 + 0.81) / 3 = 0.87

**`_format_sources(documents)`**
- Extract metadata: filename, relevance score
- Show users where answer came from (transparency)

**5. `_generate_contact_response(query: str) -> Dict`**
- Purpose: Format database contact results

**6. `_generate_location_response(query: str) -> Dict`**
- Purpose: Format database location results

**7. `_generate_ai_fallback_response(query: str) -> Dict`**
- Purpose: Handle out-of-scope queries gracefully

**8. `generate_response(query: str, intent: str) -> Dict`**
- Purpose: Main entry point - routes to correct handler

#### ğŸ–¥ï¸ Frontend - Streamlit

**What is Streamlit?**
- Streamlit = Python web framework for data apps

**Why Streamlit?**
- âœ… Write web UI in pure Python (no HTML/CSS/JavaScript)
- âœ… Auto-refreshes on code changes
- âœ… Built-in chat components (`st.chat_message`, `st.chat_input`)
- âœ… Fast prototyping (build UI in 50 lines!)

##### **Key Components:**

1. **Page Configuration:** `st.set_page_config`
2. **Sidebar:** `st.sidebar`
3. **Session State:** Conversation memory and Chat History [HW]
4. **Chat Input & API Call:** `st.chat_input`

#### ğŸš€ Running the Application

```bash
# Start backend
uvicorn api.main:app --reload

# Start frontend (on another terminal with .venv activated)
streamlit run frontend.py
```

#### â“ Common Questions

**Q: Why separate frontend and backend?**
- A: Scalability. Backend can serve multiple frontends (web, mobile, API users).

**Q: Can we use React instead of Streamlit?**
- A: Yes! Backend API is framework-agnostic. Just POST to `/api/chat`.

**Q: Why not format in chat.py directly?**
- A: Separation of concerns. `response.py` is reusable across different endpoints.

**Q: How to deploy to production?**
- A: Backend â†’ Railway/Render. Frontend â†’ Streamlit Cloud (free tier).

---

### ğŸ“… DAY 5+6: Chat System + FastAPI

**ğŸ¯ Learning Objectives:**
- Understand FastAPI application structure
- Learn request/response flow
- Master the chat endpoint orchestration

#### ğŸ“„ main.py - The Entry Point

**Purpose:** Entry point of the backend

**Key Idea:**
- Nothing intelligent happens here
- It does not answer questions
- It sets up everything needed so other files can work

##### **Key Components:**

**1. `app = FastAPI(...)`**
- App is the control center of the backend
- Every endpoint, rule, and config is attached to it

**2. CORS Middleware Block**
- Frontend and backend usually run on different ports
- Browsers block such requests by default

**CORS Configuration:**
- `allow_origins` â†’ Who can access the backend
- `allow_methods` â†’ What HTTP actions are allowed
- `allow_headers` â†’ What headers are accepted
- `allow_credentials` â†’ Whether cookies/auth can pass

**3. `init_db()`**
- Database tables exist before any request
- Backend never crashes due to missing tables
- Reads database models
- Creates tables if missing
- Skips if already present

**4. `app.include_router(...)`**
- A router is a group of related endpoints
- Example: chat routes live in `chat.py`
- Connects `/api/chat` â†’ logic in `chat.py`
- Adds structure and modularity

**5. Root Endpoint `/`**
- Helpful for debugging, deployment checks, dev sanity checks

**6. Health Check `/health`**
- Every production backend has a health endpoint
- It answers only one thing: "Am I alive?"

#### ğŸ“„ chat.py - The Orchestrator

**Purpose:** Where user input becomes an intelligent response

**Responsibilities:**
- Receiving user queries
- Validating input
- Classifying intent
- Fetching data (DB / RAG)
- Using AI when needed
- Returning a structured response

##### **Chat Endpoint: `/api/chat`**

**Role:**
- Single entry point for all user queries

**Handles:**
- Simple greetings
- Database lookups
- Document-based questions
- AI fallback responses

**Why one endpoint?**
- Simplifies frontend
- Centralizes logic
- Easier to debug and extend

##### **Key Function:** `chat(request: ChatRequest)`

**Explanation:**
- This function is the orchestrator â€” it doesn't do everything itself, but controls everything

##### **Request & Response Models**

**`ChatRequest`**

**Purpose:**
- Guarantees valid input
- Prevents malformed data
- Makes API predictable

**`ChatResponse`**

**Purpose:**
- Standardizes backend output
- Makes frontend rendering easy

**Fields:**
- `answer` â†’ Final message
- `intent` â†’ What the system understood
- `confidence` â†’ How sure the system is
- `used_fallback` â†’ Whether AI was used
- `is_multi_intent` â†’ Multiple meanings detected
- `all_intents` â†’ Ranked intent candidates

##### **Intent Classification Pipeline**

**Key Function:** `classify_detailed`

**Purpose:**
- The system decides what the user wants, not how to answer yet

**Types of intents:**
- `db_contact`
- `db_location`
- `faculty_info`
- `rag`
- `small_talk` [HW][greetings]
- `ai_fallback`

**Why classification first?**
- Avoids unnecessary DB calls
- Prevents wrong answers

**Important classification outputs:**
- `primary_intent`
- `confidence`
- `needs_fallback`
- `is_multi_intent`
- `all_intents`

##### **Handlers & Data Retrieval**

**Main routing decision:** Based on `primary_intent`

**Important Handler Functions:**
- `try_get_contact()` - Search for contact information
- `try_get_location()` - Search for locations
- `try_get_faculty()` - Search for faculty information
- `try_get_rag()` - Retrieve from RAG system
- `fallback_ai_response()` - Handle unknown queries

##### **Response Formatting**

Final step before your query is sent, processed through a number of steps and ready to be printed in JSON format â†’ formatting is required to return in user-friendly form

---

## ğŸ“ Course Summary

### Dear Students,

Over the past 6 days, we built **Campus Companion**, an AI-powered chatbot that helps students find contact information, locations, and academic policies through a beautiful Streamlit interface. 

#### ğŸ—ï¸ System Architecture

The system uses a **3-layer architecture**:
1. **Frontend** (Streamlit for UI)
2. **Backend** (FastAPI for API server)
3. **Core Intelligence** (classification, database handlers, RAG, and AI formatting)

#### ğŸ”„ Request Flow

When a user asks "Roy canteen phone", the request flows through:
1. **Pydantic validation**
2. **3-level intent classification** (keywords/ML/LLM)
3. **Routing to appropriate handler** (`try_get_contact` searches the database with fuzzy matching)
4. **AI formatting** (Mistral-7B converts raw data to natural language)
5. **Structured JSON response** displayed in the frontend

#### ğŸ› ï¸ Technologies Used

**Modern Stack:**
- **FastAPI** (REST API)
- **SQLAlchemy** (database ORM)
- **Scikit-learn** (ML classification)
- **ChromaDB** (vector database for RAG)
- **HuggingFace** (embeddings and LLM)

**Production-Grade Principles:**
- âœ… Separation of concerns
- âœ… Graceful degradation (fallback mechanisms)
- âœ… Comprehensive error handling
- âœ… Type safety with Pydantic
- âœ… Extensive logging

#### ğŸ’¡ Key Innovation

Our **hybrid approach** combines:
- **Structured database queries** for contacts/locations
- **RAG (Retrieval-Augmented Generation)** for document-based questions like "How to calculate CGPA?"
  - Uses semantic search to find relevant PDF chunks
  - Generates contextual answers

#### ğŸ¯ What You've Learned

1. **Full-stack development** (frontend + backend + database)
2. **AI/ML integration** (classification, embeddings, LLMs)
3. **Software engineering** (clean architecture, error handling, API design)
4. **Real-world application** that solves actual campus problems

#### ğŸš€ Real-World Applications

This same architecture can be adapted for:
- ğŸ¥ Hospital assistants
- ğŸ¢ Corporate helpdesks
- ğŸ›’ E-commerce support
- ğŸ“š Any domain requiring intelligent information retrieval

#### ğŸ”§ Next Steps

You're now ready to:
- **Extend** this system (add new intents, multilingual support)
- **Improve** accuracy (fine-tune classifiers, better RAG strategies)
- **Deploy** to production (Railway/Render/AWS)
- **Add** advanced features (voice input, analytics dashboards)

#### ğŸ‰ Congratulations!

You didn't just learn to code, you learned to **think like a software engineer**, understanding:
- Why each component exists
- How they communicate
- When to use different approaches

These are skills that companies actively seek in full-stack AI developers.

### **Now go build something amazing! ğŸš€**

---

## ğŸ† Skills Mastered

**FastAPI** + **Streamlit** + **SQLAlchemy** + **ChromaDB** + **HuggingFace** + **RAG** + **Clean Architecture**

**Keep coding, keep learning, keep building! ğŸ’™**

---

## ğŸ“ Support

For questions or issues, please refer to the implementation guide above or contact the development team.

---

**Made with â¤ï¸ for NIT Durgapur**
