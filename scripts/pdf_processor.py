# ============================== DAY - 2 ================================ #
"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                  PDF TEXT EXTRACTION WITH OCR                            â•‘
â•‘            Extracts Text from PDFs with Smart Fallback                   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“ FILE ROLE IN PROJECT:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
This file extracts text from PDF documents using multiple strategies:
1. Direct text extraction (fast) - for digital PDFs
2. OCR (slow but accurate) - for scanned/image-based PDFs

It's the FIRST STEP in the RAG data ingestion pipeline.

ğŸ”— HOW IT FITS IN THE ARCHITECTURE:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   DATA INGESTION PIPELINE                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  [1] PDF FILES (data/pdfs/) â† INPUT                                 â”‚
â”‚      â€¢ academic_rules.pdf                                           â”‚
â”‚      â€¢ hostel_guidelines.pdf                                        â”‚
â”‚       â†“                                                             â”‚
â”‚  [2] THIS FILE (scripts/pdf_processor.py) â† YOU ARE HERE!           â”‚
â”‚      â€¢ Try PyPDF2 first (fast text extraction)                      â”‚
â”‚      â€¢ Fallback to OCR if needed (slower but works on scans)        â”‚
â”‚      â€¢ Output: Plain text strings                                   â”‚
â”‚       â†“                                                             â”‚
â”‚  [3] TEXT CHUNKING (scripts/chunking.py)                            â”‚
â”‚      â€¢ Split text into 512-word chunks                              â”‚
â”‚       â†“                                                             â”‚
â”‚  [4] EMBEDDINGS (scripts/ingest_pdfs.py)                            â”‚
â”‚      â€¢ Convert chunks to vectors                                    â”‚
â”‚       â†“                                                             â”‚
â”‚  [5] CHROMADB STORAGE (data/rag_docs/)                              â”‚
â”‚      â€¢ Store for semantic search                                    â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ¯ WHY MULTIPLE EXTRACTION METHODS?
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Different PDFs require different approaches:

1. DIGITAL PDFs (text-based):
   â€¢ Created from Word, LaTeX, web browsers
   â€¢ Text is embedded in PDF structure
   â€¢ Fast extraction: PyPDF2, pdfplumber
   â€¢ Example: Modern academic papers, official documents

2. SCANNED PDFs (image-based):
   â€¢ Created from photocopies, phone scans
   â€¢ Text is pixels, not characters
   â€¢ Requires OCR (Optical Character Recognition)
   â€¢ Example: Old books, handwritten forms, photos

SMART FALLBACK STRATEGY:
  1. Try PyPDF2 first (< 1 second)
  2. Check if result has enough text (>100 chars)
  3. If insufficient, use OCR (~10-30 seconds per page)

ğŸ’¡ EXTRACTION METHODS COMPARED:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Method         Speed      Quality    Works On
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
PyPDF2         âš¡ Fast    Good       Digital PDFs only
pdfplumber     âš¡ Fast    Better     Digital PDFs, tables
Tesseract OCR  ğŸŒ Slow    Excellent  Everything (images, scans)

ğŸ“Š EXAMPLE OUTPUT:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Input: academic_rules.pdf

Output:
{
    'filename': 'academic_rules.pdf',
    'text': 'CGPA Calculation Rules\\n\\nThe CGPA is calculated...',
    'pages': 10,
    'method': 'text_extraction',  # or 'ocr'
    'path': '/full/path/to/academic_rules.pdf'
}

ğŸ’» USAGE:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    from scripts.pdf_processor import PDFProcessor
    
    # Initialize processor
    processor = PDFProcessor(ocr_enabled=True)
    
    # Process single PDF
    result = processor.extract_text_from_pdf('data/pdfs/rules.pdf')
    print(result['text'])
    
    # Process entire directory
    results = processor.process_directory('data/pdfs')
    for doc in results:
        print(f"{doc['filename']}: {len(doc['text'])} chars")

ğŸ”§ DEPENDENCIES:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Required packages:
  â€¢ PyPDF2: Basic PDF text extraction
  â€¢ pdfplumber: Better extraction for complex layouts
  â€¢ pytesseract: Python wrapper for Tesseract OCR
  â€¢ pdf2image: Convert PDF pages to images for OCR
  â€¢ Pillow (PIL): Image processing

System requirements for OCR:
  macOS:   brew install tesseract poppler
  Ubuntu:  apt install tesseract-ocr poppler-utils
  Windows: Download from GitHub (tesseract, poppler)

âš ï¸ TROUBLESHOOTING:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Error: "tesseract not found"
  â†’ Install: brew install tesseract (macOS)
  â†’ Or disable OCR: PDFProcessor(ocr_enabled=False)

Error: "poppler not found"
  â†’ Install: brew install poppler (macOS)
  â†’ Needed for pdf2image

Error: "Extraction returned empty string"
  â†’ Enable OCR: PDFProcessor(ocr_enabled=True)
  â†’ Check if PDF is corrupted

Slow OCR performance:
  â†’ Reduce DPI: convert_from_path(path, dpi=150)
  â†’ Default is 300 DPI (high quality, slower)
  â†’ 150 DPI: 2-4x faster, slightly lower accuracy

ğŸ“ NOTES:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â€¢ First extraction attempt uses PyPDF2 (fastest)
â€¢ OCR only triggered if text < 100 characters
â€¢ OCR processes at 300 DPI for best quality
â€¢ Each page takes ~10-15 seconds with OCR
â€¢ 100-page PDF with OCR: ~15-25 minutes
â€¢ Consider batch processing large PDFs overnight
"""


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# IMPORTS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

import os
import logging
from pathlib import Path
from typing import List,Dict

import PyPDF2
import pytesseract
from pdf2image import convert_from_path
from PIL import Image

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# LOGGING CONFIGURATION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ===========================================================================
# PDF PROCESSOR CLASS
# ===========================================================================

class PDFProcessor:
    
    def __init__(self,ocr_enabled:bool = True):
        self.ocr_enabled = ocr_enabled

    def extract_text_from_pdf(self,pdf_path:str)->Dict[str,any]:
        
        pdf_path = Path(pdf_path)

        if not pdf_path.exists():
            raise FileNotFoundError(f"PDF not found:{pdf_path}")
        
        logger.info(f"Processing:{pdf_path.name}")

        text=self._extract_text_pypdf(pdf_path)
        method="text_extraction"

        if not text or len(text.strip())<100:
            
            if self.ocr_enabled:
                logger.info(f"Text extraction insufficient.Using OCR for {pdf_path.name}")
                text = self._extract_text_ocr(pdf_path)
                method = "ocr"
            else:
                logger.warning(f"OCR disabled.Skipping {pdf_path.name}")

        with open(pdf_path,'rb') as f:
            pdf_reader = PyPDF2.PdfReader(f)
            page_count = len(pdf_reader.pages)

        return{
            'filename':pdf_path.name,
            'text':text.strip(),
            'pages':page_count,
            'method':method,
            'path':str(pdf_path)
        }  

    def _extract_text_pypdf(self,pdf_path:Path)->str:

        try :
            with open(pdf_path,'rb') as f:
                pdf_reader = PyPDF2.PdfReader(f)
                text = ""

                for page in pdf_reader.pages:
                    text+= page.extract_text()+"\n"
                return text
        except Exception as e:
            logger.error(f"PyPDF2 extraction failed : {e}")
            return ""
    
    def _extract_text_ocr(self,pdf_path: Path) -> str:
        try:
            images = convert_from_path(pdf_path,dpi=300)
            text= ""

            for i, image in enumerate(images):
                logger.info(f"OCR processing page {i+1}/{len(images)}")

                page_text = pytesseract.image_to_string(image,lang='eng')

                text+= page_text+'\n'
            return text
        
        except Exception as e:
            logger.error(f"OCR extraction failed:{e}") 
            return ""

    def process_directory(self,pdf_dir:str)-> List[Dict]:
        pdf_dir=Path(pdf_dir)

        pdf_files = list(pdf_dir.glob('*.pdf'))

        if not pdf_files:
            logger.warning(f"No PDF files found in {pdf_dir}")
            return []
        
        logger.info(f"Found {len(pdf_files)} PDF files")

        results = []

        for pdf_file in pdf_files:
            
            try:
                result = self.extract_text_from_pdf(pdf_file)
                results.append(result)
            
            except Exception as e:
                logger.error(f"failed to process {pdf_file.name}:{e}")

        return results
